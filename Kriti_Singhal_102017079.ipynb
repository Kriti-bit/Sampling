{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kriti Singhal\n",
    "### 102017079"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read in the data\n",
    "df = pd.read_csv('./Creditcard_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      1  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform eda\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 772 entries, 0 to 771\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Time    772 non-null    int64  \n",
      " 1   V1      772 non-null    float64\n",
      " 2   V2      772 non-null    float64\n",
      " 3   V3      772 non-null    float64\n",
      " 4   V4      772 non-null    float64\n",
      " 5   V5      772 non-null    float64\n",
      " 6   V6      772 non-null    float64\n",
      " 7   V7      772 non-null    float64\n",
      " 8   V8      772 non-null    float64\n",
      " 9   V9      772 non-null    float64\n",
      " 10  V10     772 non-null    float64\n",
      " 11  V11     772 non-null    float64\n",
      " 12  V12     772 non-null    float64\n",
      " 13  V13     772 non-null    float64\n",
      " 14  V14     772 non-null    float64\n",
      " 15  V15     772 non-null    float64\n",
      " 16  V16     772 non-null    float64\n",
      " 17  V17     772 non-null    float64\n",
      " 18  V18     772 non-null    float64\n",
      " 19  V19     772 non-null    float64\n",
      " 20  V20     772 non-null    float64\n",
      " 21  V21     772 non-null    float64\n",
      " 22  V22     772 non-null    float64\n",
      " 23  V23     772 non-null    float64\n",
      " 24  V24     772 non-null    float64\n",
      " 25  V25     772 non-null    float64\n",
      " 26  V26     772 non-null    float64\n",
      " 27  V27     772 non-null    float64\n",
      " 28  V28     772 non-null    float64\n",
      " 29  Amount  772 non-null    float64\n",
      " 30  Class   772 non-null    int64  \n",
      "dtypes: float64(29), int64(2)\n",
      "memory usage: 187.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>283.005181</td>\n",
       "      <td>-0.176963</td>\n",
       "      <td>0.217169</td>\n",
       "      <td>0.875172</td>\n",
       "      <td>0.285628</td>\n",
       "      <td>-0.005029</td>\n",
       "      <td>0.159081</td>\n",
       "      <td>0.123329</td>\n",
       "      <td>-0.057547</td>\n",
       "      <td>-0.030384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004888</td>\n",
       "      <td>-0.096995</td>\n",
       "      <td>-0.040344</td>\n",
       "      <td>-0.002501</td>\n",
       "      <td>0.114337</td>\n",
       "      <td>0.022782</td>\n",
       "      <td>0.023353</td>\n",
       "      <td>-0.017045</td>\n",
       "      <td>68.668290</td>\n",
       "      <td>0.011658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>171.834196</td>\n",
       "      <td>1.294724</td>\n",
       "      <td>1.173401</td>\n",
       "      <td>1.031878</td>\n",
       "      <td>1.258758</td>\n",
       "      <td>1.098143</td>\n",
       "      <td>1.225682</td>\n",
       "      <td>0.852075</td>\n",
       "      <td>0.830144</td>\n",
       "      <td>0.878183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.609335</td>\n",
       "      <td>0.607228</td>\n",
       "      <td>0.358724</td>\n",
       "      <td>0.621507</td>\n",
       "      <td>0.429667</td>\n",
       "      <td>0.484227</td>\n",
       "      <td>0.300934</td>\n",
       "      <td>0.278332</td>\n",
       "      <td>197.838269</td>\n",
       "      <td>0.107411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.093248</td>\n",
       "      <td>-12.114213</td>\n",
       "      <td>-5.694973</td>\n",
       "      <td>-4.657545</td>\n",
       "      <td>-6.631951</td>\n",
       "      <td>-3.498447</td>\n",
       "      <td>-4.925568</td>\n",
       "      <td>-7.494658</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.134608</td>\n",
       "      <td>-2.776923</td>\n",
       "      <td>-3.553381</td>\n",
       "      <td>-1.867208</td>\n",
       "      <td>-1.389079</td>\n",
       "      <td>-1.243924</td>\n",
       "      <td>-2.377933</td>\n",
       "      <td>-2.735623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>126.500000</td>\n",
       "      <td>-0.896416</td>\n",
       "      <td>-0.174684</td>\n",
       "      <td>0.308677</td>\n",
       "      <td>-0.460058</td>\n",
       "      <td>-0.534567</td>\n",
       "      <td>-0.630717</td>\n",
       "      <td>-0.296289</td>\n",
       "      <td>-0.167880</td>\n",
       "      <td>-0.517068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.213746</td>\n",
       "      <td>-0.525289</td>\n",
       "      <td>-0.176915</td>\n",
       "      <td>-0.379766</td>\n",
       "      <td>-0.166227</td>\n",
       "      <td>-0.313631</td>\n",
       "      <td>-0.047868</td>\n",
       "      <td>-0.033083</td>\n",
       "      <td>5.987500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>282.000000</td>\n",
       "      <td>-0.382618</td>\n",
       "      <td>0.285843</td>\n",
       "      <td>0.905435</td>\n",
       "      <td>0.395919</td>\n",
       "      <td>-0.116612</td>\n",
       "      <td>-0.109581</td>\n",
       "      <td>0.116329</td>\n",
       "      <td>0.034755</td>\n",
       "      <td>-0.082270</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075802</td>\n",
       "      <td>-0.076551</td>\n",
       "      <td>-0.048353</td>\n",
       "      <td>0.091886</td>\n",
       "      <td>0.143723</td>\n",
       "      <td>-0.026414</td>\n",
       "      <td>0.023199</td>\n",
       "      <td>0.021034</td>\n",
       "      <td>16.665000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>432.000000</td>\n",
       "      <td>1.110739</td>\n",
       "      <td>0.885745</td>\n",
       "      <td>1.532969</td>\n",
       "      <td>1.117559</td>\n",
       "      <td>0.452818</td>\n",
       "      <td>0.482972</td>\n",
       "      <td>0.575390</td>\n",
       "      <td>0.252395</td>\n",
       "      <td>0.412261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095149</td>\n",
       "      <td>0.307438</td>\n",
       "      <td>0.070085</td>\n",
       "      <td>0.426339</td>\n",
       "      <td>0.425798</td>\n",
       "      <td>0.260408</td>\n",
       "      <td>0.112199</td>\n",
       "      <td>0.087023</td>\n",
       "      <td>55.527500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>581.000000</td>\n",
       "      <td>1.586093</td>\n",
       "      <td>5.267376</td>\n",
       "      <td>3.772857</td>\n",
       "      <td>4.075817</td>\n",
       "      <td>7.672544</td>\n",
       "      <td>5.122103</td>\n",
       "      <td>4.808426</td>\n",
       "      <td>2.134599</td>\n",
       "      <td>5.459274</td>\n",
       "      <td>...</td>\n",
       "      <td>5.273420</td>\n",
       "      <td>1.574750</td>\n",
       "      <td>3.150413</td>\n",
       "      <td>1.215279</td>\n",
       "      <td>1.136720</td>\n",
       "      <td>3.087444</td>\n",
       "      <td>2.490503</td>\n",
       "      <td>1.575380</td>\n",
       "      <td>3828.040000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Time          V1          V2          V3          V4          V5  \\\n",
       "count  772.000000  772.000000  772.000000  772.000000  772.000000  772.000000   \n",
       "mean   283.005181   -0.176963    0.217169    0.875172    0.285628   -0.005029   \n",
       "std    171.834196    1.294724    1.173401    1.031878    1.258758    1.098143   \n",
       "min      0.000000   -6.093248  -12.114213   -5.694973   -4.657545   -6.631951   \n",
       "25%    126.500000   -0.896416   -0.174684    0.308677   -0.460058   -0.534567   \n",
       "50%    282.000000   -0.382618    0.285843    0.905435    0.395919   -0.116612   \n",
       "75%    432.000000    1.110739    0.885745    1.532969    1.117559    0.452818   \n",
       "max    581.000000    1.586093    5.267376    3.772857    4.075817    7.672544   \n",
       "\n",
       "               V6          V7          V8          V9  ...         V21  \\\n",
       "count  772.000000  772.000000  772.000000  772.000000  ...  772.000000   \n",
       "mean     0.159081    0.123329   -0.057547   -0.030384  ...    0.004888   \n",
       "std      1.225682    0.852075    0.830144    0.878183  ...    0.609335   \n",
       "min     -3.498447   -4.925568   -7.494658   -2.770089  ...   -4.134608   \n",
       "25%     -0.630717   -0.296289   -0.167880   -0.517068  ...   -0.213746   \n",
       "50%     -0.109581    0.116329    0.034755   -0.082270  ...   -0.075802   \n",
       "75%      0.482972    0.575390    0.252395    0.412261  ...    0.095149   \n",
       "max      5.122103    4.808426    2.134599    5.459274  ...    5.273420   \n",
       "\n",
       "              V22         V23         V24         V25         V26         V27  \\\n",
       "count  772.000000  772.000000  772.000000  772.000000  772.000000  772.000000   \n",
       "mean    -0.096995   -0.040344   -0.002501    0.114337    0.022782    0.023353   \n",
       "std      0.607228    0.358724    0.621507    0.429667    0.484227    0.300934   \n",
       "min     -2.776923   -3.553381   -1.867208   -1.389079   -1.243924   -2.377933   \n",
       "25%     -0.525289   -0.176915   -0.379766   -0.166227   -0.313631   -0.047868   \n",
       "50%     -0.076551   -0.048353    0.091886    0.143723   -0.026414    0.023199   \n",
       "75%      0.307438    0.070085    0.426339    0.425798    0.260408    0.112199   \n",
       "max      1.574750    3.150413    1.215279    1.136720    3.087444    2.490503   \n",
       "\n",
       "              V28       Amount       Class  \n",
       "count  772.000000   772.000000  772.000000  \n",
       "mean    -0.017045    68.668290    0.011658  \n",
       "std      0.278332   197.838269    0.107411  \n",
       "min     -2.735623     0.000000    0.000000  \n",
       "25%     -0.033083     5.987500    0.000000  \n",
       "50%      0.021034    16.665000    0.000000  \n",
       "75%      0.087023    55.527500    0.000000  \n",
       "max      1.575380  3828.040000    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      False\n",
       "V1        False\n",
       "V2        False\n",
       "V3        False\n",
       "V4        False\n",
       "V5        False\n",
       "V6        False\n",
       "V7        False\n",
       "V8        False\n",
       "V9        False\n",
       "V10       False\n",
       "V11       False\n",
       "V12       False\n",
       "V13       False\n",
       "V14       False\n",
       "V15       False\n",
       "V16       False\n",
       "V17       False\n",
       "V18       False\n",
       "V19       False\n",
       "V20       False\n",
       "V21       False\n",
       "V22       False\n",
       "V23       False\n",
       "V24       False\n",
       "V25       False\n",
       "V26       False\n",
       "V27       False\n",
       "V28       False\n",
       "Amount    False\n",
       "Class     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns with missing values\n",
    "df.isnull().sum() != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    763\n",
       "1      9\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class distribution\n",
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df['Class'].value_counts().plot(kind='bar', title='Class Distribution', color=['orange', 'blue'])\n",
    "for i, v in enumerate(df['Class'].value_counts()):\n",
    "    plt.text(i, v, str(v), color='black', ha='center', va='bottom')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample the minority class\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=123)\n",
    "X, y = sm.fit_resample(df.drop('Class', axis=1), df['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V20       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...  0.251412 -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ... -0.069083 -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...  0.524980  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ... -0.208038 -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...  0.408542 -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    763\n",
       "1    763\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update df as combination of X and y\n",
    "df = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGuCAYAAAC6DP3dAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxgklEQVR4nO3de3QU9f3/8dcmIUsI7EYi2U00QEQqCXJRaGGBeiMSMXj5GlSUYkQKLQ1WiKaYlovGCy1tRbHFVA+C3y/yteJXUWlBA1j4WdYQ06KIgDdqUNyESrMLWBJI5veHJ1NXQNkksJ+E5+OcOcf9fD4z8x6Ow7yYnfmsw7IsSwAAAAaJiXYBAAAAX0dAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0AB2oCePXvq1ltvjXYZLXbPPffI4XCckn1dcskluuSSS+zPf/nLX+RwOPTcc8+dkv3feuut6tmz5ynZF9AeEVCAKPrwww/1ox/9SOecc446duwol8ul4cOH65FHHtG///3vaJf3jZYuXSqHw2EvHTt2VFpamnJycrRw4ULt37+/VfazZ88e3XPPPdqyZUurbK81mVwb0NbFRbsA4HT1pz/9Sddff72cTqduueUWnX/++aqvr9frr7+uoqIibdu2TY8//ni0y/xWJSUlysjI0OHDhxUIBPSXv/xF06dP10MPPaSXXnpJ/fv3t8fOmjVLd999d0Tb37Nnj+6991717NlTAwcOPOH1Xn311Yj20xzfVNsTTzyhxsbGk14D0F4RUIAo2LVrl8aNG6cePXpo/fr1Sk1NtfsKCgr0wQcf6E9/+lMUKzxxo0eP1uDBg+3PxcXFWr9+vcaMGaOrr75a27dvV0JCgiQpLi5OcXEn96+dL774Qp06dVJ8fPxJ3c+36dChQ1T3D7R1fMUDRMH8+fN14MABLV68OCycNDn33HN1xx13HHf9ffv26a677lK/fv3UuXNnuVwujR49Wm+99dZRYx999FH17dtXnTp10hlnnKHBgwdr+fLldv/+/fs1ffp09ezZU06nUykpKbr88sv1t7/9rdnHd9lll2n27Nn6+OOPtWzZMrv9WM+glJWVacSIEUpKSlLnzp113nnn6ec//7mkL58b+e53vytJmjhxov110tKlSyV9+ZzJ+eefr8rKSl100UXq1KmTve7Xn0Fp0tDQoJ///Ofyer1KTEzU1Vdfrd27d4eNOd4zP1/d5rfVdqxnUA4ePKg777xT6enpcjqdOu+88/Sb3/xGX/9ReYfDoWnTpmnlypU6//zz5XQ61bdvX61Zs+bYf+BAO8QdFCAKXn75ZZ1zzjkaNmxYs9b/6KOPtHLlSl1//fXKyMhQdXW1/vCHP+jiiy/Wu+++q7S0NElffs3w05/+VGPHjtUdd9yhQ4cO6e2331Z5ebluvvlmSdKPf/xjPffcc5o2bZqysrL0+eef6/XXX9f27dt14YUXNvsYJ0yYoJ///Od69dVXNXny5GOO2bZtm8aMGaP+/furpKRETqdTH3zwgf76179KkjIzM1VSUqI5c+ZoypQp+v73vy9JYX9un3/+uUaPHq1x48bpBz/4gTwezzfW9cADD8jhcGjmzJmqqanRww8/rOzsbG3ZssW+03MiTqS2r7IsS1dffbVee+01TZo0SQMHDtQrr7yioqIiffrpp1qwYEHY+Ndff13PP/+8fvKTn6hLly5auHCh8vLyVFVVpeTk5BOuE2izLACnVDAYtCRZ11xzzQmv06NHDys/P9/+fOjQIauhoSFszK5duyyn02mVlJTYbddcc43Vt2/fb9y22+22CgoKTriWJkuWLLEkWRUVFd+47QsuuMD+PHfuXOurf+0sWLDAkmTt3bv3uNuoqKiwJFlLliw5qu/iiy+2JFmlpaXH7Lv44ovtz6+99polyTrrrLOsUChktz/77LOWJOuRRx6x277+5328bX5Tbfn5+VaPHj3szytXrrQkWffff3/YuLFjx1oOh8P64IMP7DZJVnx8fFjbW2+9ZUmyHn300aP2BbRHfMUDnGKhUEiS1KVLl2Zvw+l0Kibmy9O3oaFBn3/+uf31yFe/mklKStInn3yiioqK424rKSlJ5eXl2rNnT7PrOZ7OnTt/49s8SUlJkqQXX3yx2Q+UOp1OTZw48YTH33LLLWF/9mPHjlVqaqr+/Oc/N2v/J+rPf/6zYmNj9dOf/jSs/c4775RlWVq9enVYe3Z2tnr16mV/7t+/v1wulz766KOTWidgCgIKcIq5XC5JatFruI2NjVqwYIF69+4tp9OpM888U926ddPbb7+tYDBoj5s5c6Y6d+6s733ve+rdu7cKCgrsr0+azJ8/X++8847S09P1ve99T/fcc0+rXQQPHDjwjUHsxhtv1PDhw/XDH/5QHo9H48aN07PPPhtRWDnrrLMieiC2d+/eYZ8dDofOPfdc/eMf/zjhbTTHxx9/rLS0tKP+PDIzM+3+r+revftR2zjjjDP0r3/96+QVCRiEgAKcYi6XS2lpaXrnnXeavY0HH3xQhYWFuuiii7Rs2TK98sorKisrU9++fcMu7pmZmdq5c6eeeeYZjRgxQv/3f/+nESNGaO7cufaYG264QR999JEeffRRpaWl6de//rX69u171L/oI/XJJ58oGAzq3HPPPe6YhIQEbdy4UWvXrtWECRP09ttv68Ybb9Tll1+uhoaGE9pPJM+NnKjjTSZ3ojW1htjY2GO2W197oBZorwgoQBSMGTNGH374ofx+f7PWf+6553TppZdq8eLFGjdunEaNGqXs7GzV1tYeNTYxMVE33nijlixZoqqqKuXm5uqBBx7QoUOH7DGpqan6yU9+opUrV2rXrl1KTk7WAw880NzDkyT9z//8jyQpJyfnG8fFxMRo5MiReuihh/Tuu+/qgQce0Pr16/Xaa69JOn5YaK73338/7LNlWfrggw/C3rg544wzjvln+fW7HJHU1qNHD+3Zs+eoO2c7duyw+wH8BwEFiIKf/exnSkxM1A9/+ENVV1cf1f/hhx/qkUceOe76sbGxR/1LesWKFfr000/D2j7//POwz/Hx8crKypJlWTp8+LAaGhrCvhKSpJSUFKWlpamuri7Sw7KtX79e9913nzIyMjR+/Pjjjtu3b99RbU0TnjXtPzExUZKOGRia47//+7/DQsJzzz2nzz77TKNHj7bbevXqpTfeeEP19fV226pVq456HTmS2q688ko1NDTod7/7XVj7ggUL5HA4wvYPgNeMgajo1auXli9frhtvvFGZmZlhM8lu2rRJK1as+Mbf3hkzZoxKSko0ceJEDRs2TFu3btXTTz+tc845J2zcqFGj5PV6NXz4cHk8Hm3fvl2/+93vlJubqy5duqi2tlZnn322xo4dqwEDBqhz585au3atKioq9Nvf/vaEjmX16tXasWOHjhw5ourqaq1fv15lZWXq0aOHXnrpJXXs2PG465aUlGjjxo3Kzc1Vjx49VFNTo0WLFunss8/WiBEj7D+rpKQklZaWqkuXLkpMTNSQIUOUkZFxQvV9XdeuXTVixAhNnDhR1dXVevjhh3XuueeGvQr9wx/+UM8995yuuOIK3XDDDfrwww+1bNmysIdWI63tqquu0qWXXqpf/OIX+sc//qEBAwbo1Vdf1Ysvvqjp06cftW3gtBfVd4iA09x7771nTZ482erZs6cVHx9vdenSxRo+fLj16KOPWocOHbLHHes14zvvvNNKTU21EhISrOHDh1t+v/+o12D/8Ic/WBdddJGVnJxsOZ1Oq1evXlZRUZEVDAYty7Ksuro6q6ioyBowYIDVpUsXKzEx0RowYIC1aNGib6296TXjpiU+Pt7yer3W5Zdfbj3yyCNhr/I2+fprxuvWrbOuueYaKy0tzYqPj7fS0tKsm266yXrvvffC1nvxxRetrKwsKy4uLuy13osvvvi4r1Ef7zXj//3f/7WKi4utlJQUKyEhwcrNzbU+/vjjo9b/7W9/a5111lmW0+m0hg8fbr355ptHbfObavv6a8aWZVn79++3ZsyYYaWlpVkdOnSwevfubf3617+2Ghsbw8ZJOuar38d7/RlojxyWxRNXAADALDyDAgAAjENAAQAAxiGgAAAA40QUUBoaGjR79mxlZGQoISFBvXr10n333Rf2uqNlWZozZ45SU1OVkJCg7Ozso+Yd2Ldvn8aPHy+Xy6WkpCRNmjRJBw4caJ0jAgAAbV5EAeVXv/qVHnvsMf3ud7/T9u3b9atf/Urz58/Xo48+ao+ZP3++Fi5cqNLSUpWXlysxMVE5OTlhk0KNHz9e27ZtU1lZmVatWqWNGzdqypQprXdUAACgTYvoLZ4xY8bI4/Fo8eLFdlteXp4SEhK0bNkyWZaltLQ03XnnnbrrrrskScFgUB6PR0uXLtW4ceO0fft2ZWVlqaKiQoMHD5YkrVmzRldeeaU++eQT+2fiAQDA6SuiidqGDRumxx9/XO+9956+853v6K233tLrr7+uhx56SJK0a9cuBQIBZWdn2+u43W4NGTJEfr9f48aNk9/vV1JSkh1OpC9/tTMmJkbl5eX6r//6r6P2W1dXFzarZWNjo/bt26fk5ORWnwYbAACcHJZlaf/+/UpLS7N/kf14Igood999t0KhkPr06aPY2Fg1NDTogQcesKeyDgQCkiSPxxO2nsfjsfsCgYBSUlLCi4iLU9euXe0xXzdv3jzde++9kZQKAAAMtXv3bp199tnfOCaigPLss8/q6aef1vLly9W3b19t2bJF06dPV1pamvLz81tU7DcpLi5WYWGh/TkYDKp79+7avXu3/dP1AADAbKFQSOnp6erSpcu3jo0ooBQVFenuu+/WuHHjJEn9+vXTxx9/rHnz5ik/P19er1eSVF1drdTUVHu96upq+wfAvF6vampqwrZ75MgR7du3z17/65xOp5xO51HtLpeLgAIAQBtzIo9nRPQWzxdffHHUd0axsbFqbGyUJGVkZMjr9WrdunV2fygUUnl5uXw+nyTJ5/OptrZWlZWV9pj169ersbFRQ4YMiaQcAADQTkV0B+Wqq67SAw88oO7du6tv3776+9//roceeki33XabpC8T0fTp03X//ferd+/eysjI0OzZs5WWlqZrr71WkpSZmakrrrhCkydPVmlpqQ4fPqxp06Zp3LhxvMEDAAC+FMkvC4ZCIeuOO+6wunfvbnXs2NE655xzrF/84hdWXV2dPaaxsdGaPXu25fF4LKfTaY0cOdLauXNn2HY+//xz66abbrI6d+5suVwua+LEidb+/ftPuI5gMGhJsn+RFW1Pjx49wn4Jt2n5yU9+Yo/ZtGmTdemll1qdOnWyunTpYn3/+9+3vvjiC7v/qquustLT0y2n02l5vV7rBz/4gfXpp59G43AAfAXnN44nkut3m/w141AoJLfbrWAwyDMobdTevXvV0NBgf37nnXd0+eWX67XXXtMll1wiv9+vK664QsXFxbrqqqsUFxent956S9dcc439PNKCBQvk8/mUmpqqTz/91J57Z9OmTVE5JgBf4vzG8URy/SagwAjTp0/XqlWr9P7778vhcGjo0KG6/PLLdd99953wNl566SVde+21qqurU4cOHU5itQAiwfmNJpFcv/mxQERdfX29li1bpttuu00Oh0M1NTUqLy9XSkqKhg0bJo/Ho4svvlivv/76cbexb98+Pf300xo2bBh/eQEG4fxGcxFQEHUrV65UbW2tbr31VknSRx99JEm65557NHnyZK1Zs0YXXnihRo4cedQPT86cOVOJiYlKTk5WVVWVXnzxxVNdPoBvwPmN5iKgIOoWL16s0aNH229xNb22/qMf/UgTJ07UBRdcoAULFui8887Tk08+GbZuUVGR/v73v+vVV19VbGysbrnlFrXBby2BdovzG80V0WvGQGv7+OOPtXbtWj3//PN2W9Mkf1lZWWFjMzMzVVVVFdZ25pln6swzz9R3vvMdZWZmKj09XW+88YY97w6A6OH8RktwBwVRtWTJEqWkpCg3N9du69mzp9LS0rRz586wse+995569Ohx3G01/cvsqz8sCSB6OL/REtxBQdQ0NjZqyZIlys/PV1zcf/5XdDgcKioq0ty5czVgwAANHDhQTz31lHbs2KHnnntOklReXq6KigqNGDFCZ5xxhj788EPNnj1bvXr14l9XgAE4v9FSBBREzdq1a1VVVWXPRPxV06dP16FDhzRjxgzt27dPAwYMUFlZmXr16iVJ6tSpk55//nnNnTtXBw8eVGpqqq644grNmjXrmL/bBODU4vxGSzEPCgAAOCWYBwUAALRpfMXT1iz/9p+oRjtyc5u7wYkWOIFfoEc70va+vzi1uIMCAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYJ6KA0rNnTzkcjqOWgoICSdKhQ4dUUFCg5ORkde7cWXl5eaqurg7bRlVVlXJzc9WpUyelpKSoqKhIR44cab0jAgAAbV5EAaWiokKfffaZvZSVlUmSrr/+eknSjBkz9PLLL2vFihXasGGD9uzZo+uuu85ev6GhQbm5uaqvr9emTZv01FNPaenSpZozZ04rHhIAAGjrHJZlWc1defr06Vq1apXef/99hUIhdevWTcuXL9fYsWMlSTt27FBmZqb8fr+GDh2q1atXa8yYMdqzZ488Ho8kqbS0VDNnztTevXsVHx9/QvsNhUJyu90KBoNyuVzNLb9tWu6IdgU4lW5u9umJNsjB6X1aaf7Vt+2K5Prd7GdQ6uvrtWzZMt12221yOByqrKzU4cOHlZ2dbY/p06ePunfvLr/fL0ny+/3q16+fHU4kKScnR6FQSNu2bTvuvurq6hQKhcIWAADQfjU7oKxcuVK1tbW69dZbJUmBQEDx8fFKSkoKG+fxeBQIBOwxXw0nTf1Nfcczb948ud1ue0lPT29u2QAAoA1odkBZvHixRo8erbS0tNas55iKi4sVDAbtZffu3Sd9nwAAIHrimrPSxx9/rLVr1+r555+327xer+rr61VbWxt2F6W6ulper9ces3nz5rBtNb3l0zTmWJxOp5xOZ3NKBQAAbVCz7qAsWbJEKSkpys3NtdsGDRqkDh06aN26dXbbzp07VVVVJZ/PJ0ny+XzaunWrampq7DFlZWVyuVzKyspq7jEAAIB2JuI7KI2NjVqyZIny8/MVF/ef1d1utyZNmqTCwkJ17dpVLpdLt99+u3w+n4YOHSpJGjVqlLKysjRhwgTNnz9fgUBAs2bNUkFBAXdIAACALeKAsnbtWlVVVem22247qm/BggWKiYlRXl6e6urqlJOTo0WLFtn9sbGxWrVqlaZOnSqfz6fExETl5+erpKSkZUcBAADalRbNgxItzIOC0wbzoJxWmAfl9NL2rr4td0rmQQEAADhZCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAME7EAeXTTz/VD37wAyUnJyshIUH9+vXTm2++afdblqU5c+YoNTVVCQkJys7O1vvvvx+2jX379mn8+PFyuVxKSkrSpEmTdODAgZYfDQAAaBciCij/+te/NHz4cHXo0EGrV6/Wu+++q9/+9rc644wz7DHz58/XwoULVVpaqvLyciUmJionJ0eHDh2yx4wfP17btm1TWVmZVq1apY0bN2rKlCmtd1QAAKBNc1iWZZ3o4Lvvvlt//etf9f/+3/87Zr9lWUpLS9Odd96pu+66S5IUDAbl8Xi0dOlSjRs3Ttu3b1dWVpYqKio0ePBgSdKaNWt05ZVX6pNPPlFaWtq31hEKheR2uxUMBuVyuU60/PZhuSPaFeBUuvmET0+0Aw5O79PKiV99249Irt8R3UF56aWXNHjwYF1//fVKSUnRBRdcoCeeeMLu37VrlwKBgLKzs+02t9utIUOGyO/3S5L8fr+SkpLscCJJ2dnZiomJUXl5+TH3W1dXp1AoFLYAAID2K6KA8tFHH+mxxx5T79699corr2jq1Kn66U9/qqeeekqSFAgEJEkejydsPY/HY/cFAgGlpKSE9cfFxalr1672mK+bN2+e3G63vaSnp0dSNgAAaGMiCiiNjY268MIL9eCDD+qCCy7QlClTNHnyZJWWlp6s+iRJxcXFCgaD9rJ79+6Tuj8AABBdEQWU1NRUZWVlhbVlZmaqqqpKkuT1eiVJ1dXVYWOqq6vtPq/Xq5qamrD+I0eOaN++ffaYr3M6nXK5XGELAABovyIKKMOHD9fOnTvD2t577z316NFDkpSRkSGv16t169bZ/aFQSOXl5fL5fJIkn8+n2tpaVVZW2mPWr1+vxsZGDRkypNkHAgAA2o+4SAbPmDFDw4YN04MPPqgbbrhBmzdv1uOPP67HH39ckuRwODR9+nTdf//96t27tzIyMjR79mylpaXp2muvlfTlHZcrrrjC/mro8OHDmjZtmsaNG3dCb/AAAID2L6KA8t3vflcvvPCCiouLVVJSooyMDD388MMaP368PeZnP/uZDh48qClTpqi2tlYjRozQmjVr1LFjR3vM008/rWnTpmnkyJGKiYlRXl6eFi5c2HpHBQAA2rSI5kExBfOg4LTBPCinFeZBOb20vatvy520eVAAAABOBQIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABgnooByzz33yOFwhC19+vSx+w8dOqSCggIlJyerc+fOysvLU3V1ddg2qqqqlJubq06dOiklJUVFRUU6cuRI6xwNAABoF+IiXaFv375au3btfzYQ959NzJgxQ3/605+0YsUKud1uTZs2Tdddd53++te/SpIaGhqUm5srr9erTZs26bPPPtMtt9yiDh066MEHH2yFwwEAAO1BxAElLi5OXq/3qPZgMKjFixdr+fLluuyyyyRJS5YsUWZmpt544w0NHTpUr776qt59912tXbtWHo9HAwcO1H333aeZM2fqnnvuUXx8fMuPCAAAtHkRP4Py/vvvKy0tTeecc47Gjx+vqqoqSVJlZaUOHz6s7Oxse2yfPn3UvXt3+f1+SZLf71e/fv3k8XjsMTk5OQqFQtq2bdtx91lXV6dQKBS2AACA9iuigDJkyBAtXbpUa9as0WOPPaZdu3bp+9//vvbv369AIKD4+HglJSWFrePxeBQIBCRJgUAgLJw09Tf1Hc+8efPkdrvtJT09PZKyAQBAGxPRVzyjR4+2/7t///4aMmSIevTooWeffVYJCQmtXlyT4uJiFRYW2p9DoRAhBQCAdqxFrxknJSXpO9/5jj744AN5vV7V19ertrY2bEx1dbX9zIrX6z3qrZ6mz8d6rqWJ0+mUy+UKWwAAQPvVooBy4MABffjhh0pNTdWgQYPUoUMHrVu3zu7fuXOnqqqq5PP5JEk+n09bt25VTU2NPaasrEwul0tZWVktKQUAALQjEX3Fc9ddd+mqq65Sjx49tGfPHs2dO1exsbG66aab5Ha7NWnSJBUWFqpr165yuVy6/fbb5fP5NHToUEnSqFGjlJWVpQkTJmj+/PkKBAKaNWuWCgoK5HQ6T8oBAgCAtieigPLJJ5/opptu0ueff65u3bppxIgReuONN9StWzdJ0oIFCxQTE6O8vDzV1dUpJydHixYtstePjY3VqlWrNHXqVPl8PiUmJio/P18lJSWte1QAAKBNc1iWZUW7iEiFQiG53W4Fg8HT73mU5Y5oV4BT6eY2d3qiBRyc3qeVtnf1bblIrt/8Fg8AADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjNOigPLLX/5SDodD06dPt9sOHTqkgoICJScnq3PnzsrLy1N1dXXYelVVVcrNzVWnTp2UkpKioqIiHTlypCWlAACAdqTZAaWiokJ/+MMf1L9//7D2GTNm6OWXX9aKFSu0YcMG7dmzR9ddd53d39DQoNzcXNXX12vTpk166qmntHTpUs2ZM6f5RwEAANqVZgWUAwcOaPz48XriiSd0xhln2O3BYFCLFy/WQw89pMsuu0yDBg3SkiVLtGnTJr3xxhuSpFdffVXvvvuuli1bpoEDB2r06NG677779Pvf/1719fWtc1QAAKBNa1ZAKSgoUG5urrKzs8PaKysrdfjw4bD2Pn36qHv37vL7/ZIkv9+vfv36yePx2GNycnIUCoW0bdu2Y+6vrq5OoVAobAEAAO1XXKQrPPPMM/rb3/6mioqKo/oCgYDi4+OVlJQU1u7xeBQIBOwxXw0nTf1Nfccyb9483XvvvZGWCgAA2qiI7qDs3r1bd9xxh55++ml17NjxZNV0lOLiYgWDQXvZvXv3Kds3AAA49SIKKJWVlaqpqdGFF16ouLg4xcXFacOGDVq4cKHi4uLk8XhUX1+v2trasPWqq6vl9XolSV6v96i3epo+N435OqfTKZfLFbYAAID2K6KAMnLkSG3dulVbtmyxl8GDB2v8+PH2f3fo0EHr1q2z19m5c6eqqqrk8/kkST6fT1u3blVNTY09pqysTC6XS1lZWa10WAAAoC2L6BmULl266Pzzzw9rS0xMVHJyst0+adIkFRYWqmvXrnK5XLr99tvl8/k0dOhQSdKoUaOUlZWlCRMmaP78+QoEApo1a5YKCgrkdDpb6bAAAEBbFvFDst9mwYIFiomJUV5enurq6pSTk6NFixbZ/bGxsVq1apWmTp0qn8+nxMRE5efnq6SkpLVLAQAAbZTDsiwr2kVEKhQKye12KxgMnn7Poyx3RLsCnEo3t7nTEy3g4PQ+rbS9q2/LRXL95rd4AACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGCciALKY489pv79+8vlcsnlcsnn82n16tV2/6FDh1RQUKDk5GR17txZeXl5qq6uDttGVVWVcnNz1alTJ6WkpKioqEhHjhxpnaMBAADtQkQB5eyzz9Yvf/lLVVZW6s0339Rll12ma665Rtu2bZMkzZgxQy+//LJWrFihDRs2aM+ePbruuuvs9RsaGpSbm6v6+npt2rRJTz31lJYuXao5c+a07lEBAIA2zWFZltWSDXTt2lW//vWvNXbsWHXr1k3Lly/X2LFjJUk7duxQZmam/H6/hg4dqtWrV2vMmDHas2ePPB6PJKm0tFQzZ87U3r17FR8ff0L7DIVCcrvdCgaDcrlcLSm/7VnuiHYFOJVubtHpiTbGwel9WmnZ1bdtiuT63exnUBoaGvTMM8/o4MGD8vl8qqys1OHDh5WdnW2P6dOnj7p37y6/3y9J8vv96tevnx1OJCknJ0ehUMi+C3MsdXV1CoVCYQsAAGi/Ig4oW7duVefOneV0OvXjH/9YL7zwgrKyshQIBBQfH6+kpKSw8R6PR4FAQJIUCATCwklTf1Pf8cybN09ut9te0tPTIy0bAAC0IREHlPPOO09btmxReXm5pk6dqvz8fL377rsnozZbcXGxgsGgvezevfuk7g8AAERXXKQrxMfH69xzz5UkDRo0SBUVFXrkkUd04403qr6+XrW1tWF3Uaqrq+X1eiVJXq9XmzdvDtte01s+TWOOxel0yul0RloqAABoo1o8D0pjY6Pq6uo0aNAgdejQQevWrbP7du7cqaqqKvl8PkmSz+fT1q1bVVNTY48pKyuTy+VSVlZWS0sBAADtRER3UIqLizV69Gh1795d+/fv1/Lly/WXv/xFr7zyitxutyZNmqTCwkJ17dpVLpdLt99+u3w+n4YOHSpJGjVqlLKysjRhwgTNnz9fgUBAs2bNUkFBAXdIAACALaKAUlNTo1tuuUWfffaZ3G63+vfvr1deeUWXX365JGnBggWKiYlRXl6e6urqlJOTo0WLFtnrx8bGatWqVZo6dap8Pp8SExOVn5+vkpKS1j0qAADQprV4HpRoYB4UnDaYB+W0wjwop5e2d/VtuVMyDwoAAMDJQkABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAONEFFDmzZun7373u+rSpYtSUlJ07bXXaufOnWFjDh06pIKCAiUnJ6tz587Ky8tTdXV12Jiqqirl5uaqU6dOSklJUVFRkY4cOdLyowEAAO1CRAFlw4YNKigo0BtvvKGysjIdPnxYo0aN0sGDB+0xM2bM0Msvv6wVK1Zow4YN2rNnj6677jq7v6GhQbm5uaqvr9emTZv01FNPaenSpZozZ07rHRUAAGjTHJZlWc1dee/evUpJSdGGDRt00UUXKRgMqlu3blq+fLnGjh0rSdqxY4cyMzPl9/s1dOhQrV69WmPGjNGePXvk8XgkSaWlpZo5c6b27t2r+Pj4b91vKBSS2+1WMBiUy+Vqbvlt03JHtCvAqXRzs09PtEEOTu/TSvOvvm1XJNfvFj2DEgwGJUldu3aVJFVWVurw4cPKzs62x/Tp00fdu3eX3++XJPn9fvXr188OJ5KUk5OjUCikbdu2HXM/dXV1CoVCYQsAAGi/mh1QGhsbNX36dA0fPlznn3++JCkQCCg+Pl5JSUlhYz0ejwKBgD3mq+Gkqb+p71jmzZsnt9ttL+np6c0tGwAAtAHNDigFBQV655139Mwzz7RmPcdUXFysYDBoL7t37z7p+wQAANET15yVpk2bplWrVmnjxo06++yz7Xav16v6+nrV1taG3UWprq6W1+u1x2zevDlse01v+TSN+Tqn0ymn09mcUgEAQBsU0R0Uy7I0bdo0vfDCC1q/fr0yMjLC+gcNGqQOHTpo3bp1dtvOnTtVVVUln88nSfL5fNq6datqamrsMWVlZXK5XMrKymrJsQAAgHYiojsoBQUFWr58uV588UV16dLFfmbE7XYrISFBbrdbkyZNUmFhobp27SqXy6Xbb79dPp9PQ4cOlSSNGjVKWVlZmjBhgubPn69AIKBZs2apoKCAuyQAAEBShAHlsccekyRdcsklYe1LlizRrbfeKklasGCBYmJilJeXp7q6OuXk5GjRokX22NjYWK1atUpTp06Vz+dTYmKi8vPzVVJS0rIjAQAA7UaL5kGJFuZBwWmDeVBOK8yDcnppe1ffljtl86AAAACcDAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADBOxAFl48aNuuqqq5SWliaHw6GVK1eG9VuWpTlz5ig1NVUJCQnKzs7W+++/HzZm3759Gj9+vFwul5KSkjRp0iQdOHCgRQcCAADaj4gDysGDBzVgwAD9/ve/P2b//PnztXDhQpWWlqq8vFyJiYnKycnRoUOH7DHjx4/Xtm3bVFZWplWrVmnjxo2aMmVK848CAAC0Kw7Lsqxmr+xw6IUXXtC1114r6cu7J2lpabrzzjt11113SZKCwaA8Ho+WLl2qcePGafv27crKylJFRYUGDx4sSVqzZo2uvPJKffLJJ0pLS/vW/YZCIbndbgWDQblcruaW3zYtd0S7ApxKNzf79EQb5OD0Pq00/+rbdkVy/W7VZ1B27dqlQCCg7Oxsu83tdmvIkCHy+/2SJL/fr6SkJDucSFJ2drZiYmJUXl5+zO3W1dUpFAqFLQAAoP1q1YASCAQkSR6PJ6zd4/HYfYFAQCkpKWH9cXFx6tq1qz3m6+bNmye3220v6enprVk2AAAwTJt4i6e4uFjBYNBedu/eHe2SAADASdSqAcXr9UqSqqurw9qrq6vtPq/Xq5qamrD+I0eOaN++ffaYr3M6nXK5XGELAABov1o1oGRkZMjr9WrdunV2WygUUnl5uXw+nyTJ5/OptrZWlZWV9pj169ersbFRQ4YMac1yAABAGxUX6QoHDhzQBx98YH/etWuXtmzZoq5du6p79+6aPn267r//fvXu3VsZGRmaPXu20tLS7Dd9MjMzdcUVV2jy5MkqLS3V4cOHNW3aNI0bN+6E3uABAADtX8QB5c0339Sll15qfy4sLJQk5efna+nSpfrZz36mgwcPasqUKaqtrdWIESO0Zs0adezY0V7n6aef1rRp0zRy5EjFxMQoLy9PCxcubIXDAQAA7UGL5kGJFuZBwWmDeVBOK8yDcnppe1fflovaPCgAAACtgYACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMaJakD5/e9/r549e6pjx44aMmSINm/eHM1yAACAIaIWUP74xz+qsLBQc+fO1d/+9jcNGDBAOTk5qqmpiVZJAADAEFELKA899JAmT56siRMnKisrS6WlperUqZOefPLJaJUEAAAMEReNndbX16uyslLFxcV2W0xMjLKzs+X3+48aX1dXp7q6OvtzMBiUJIVCoZNfrGm+iHYBOKVOx//HgdPE6Xh6N123Lcv61rFRCSj//Oc/1dDQII/HE9bu8Xi0Y8eOo8bPmzdP995771Ht6enpJ61GwAiT3dGuAMBJ4j6NT+/9+/fL/S1/AFEJKJEqLi5WYWGh/bmxsVH79u1TcnKyHA5HFCvDqRAKhZSenq7du3fL5XJFuxwArYjz+/RiWZb279+vtLS0bx0blYBy5plnKjY2VtXV1WHt1dXV8nq9R413Op1yOp1hbUlJSSezRBjI5XLxFxjQTnF+nz6+7c5Jk6g8JBsfH69BgwZp3bp1dltjY6PWrVsnn88XjZIAAIBBovYVT2FhofLz8zV48GB973vf08MPP6yDBw9q4sSJ0SoJAAAYImoB5cYbb9TevXs1Z84cBQIBDRw4UGvWrDnqwVnA6XRq7ty5R33NB6Dt4/zG8TisE3nXBwAA4BTit3gAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABinTUx1j9PLP//5Tz355JPy+/0KBAKSJK/Xq2HDhunWW29Vt27dolwhAOBk4zVjGKWiokI5OTnq1KmTsrOz7XlxqqurtW7dOn3xxRd65ZVXNHjw4ChXCgA4mQgoMMrQoUM1YMAAlZaWHvVDkJZl6cc//rHefvtt+f3+KFUI4GTavXu35s6dqyeffDLapSDKCCgwSkJCgv7+97+rT58+x+zfsWOHLrjgAv373/8+xZUBOBXeeustXXjhhWpoaIh2KYgynkGBUbxerzZv3nzcgLJ582Z+DgFow1566aVv7P/oo49OUSUwHQEFRrnrrrs0ZcoUVVZWauTIkUc9g/LEE0/oN7/5TZSrBNBc1157rRwOh77p5v3Xv97F6YmveGCcP/7xj1qwYIEqKyvt27yxsbEaNGiQCgsLdcMNN0S5QgDNddZZZ2nRokW65pprjtm/ZcsWDRo0iK94QECBuQ4fPqx//vOfkqQzzzxTHTp0iHJFAFrq6quv1sCBA1VSUnLM/rfeeksXXHCBGhsbT3FlMA1f8cBYHTp0UGpqarTLANCKioqKdPDgweP2n3vuuXrttddOYUUwFXdQAACAcZjqHgAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgnP8PMmriodOLDFYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df['Class'].value_counts().plot(kind='bar', title='Class Distribution', color=['orange', 'blue'])\n",
    "for i, v in enumerate(df['Class'].value_counts()):\n",
    "    plt.text(i, v, str(v), color='black', ha='center', va='bottom')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the sample size for simple random sampling\n",
    "sample_size_srs = int(1.96**2 * 0.5 * (1 - 0.5) / 0.05**2)\n",
    "sample_size_srs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the sample size for stratified random sampling\n",
    "S = 2 # Number of Strata\n",
    "sample_size_stratified = int(1.96**2 * 0.5 * (1 - 0.5) / (0.05/S)**2)\n",
    "sample_size_stratified"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sample size for Cluster sampling\n",
    "C = 763*2/12 # Number elements in each cluster\n",
    "sample_size_cluster = int(1.96**2 * 0.5 * (1 - 0.5) / (0.05/C)**2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating samples using different techniques"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simple Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    203\n",
       "0    181\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample1 = df.sample(n=sample_size_srs, random_state=123)\n",
    "sample1['Class'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    763\n",
       "1    763\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_temp = df.groupby(df['Class'], group_keys=False).apply(lambda x: x.sample(min(len(x), sample_size_stratified)))\n",
    "sample2 = pd.DataFrame(sample_temp, columns=df.columns)\n",
    "sample2['Class'].value_counts()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cluster Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    572\n",
       "0    427\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=12, random_state=42).fit(df)\n",
    "cluster_assignments = kmeans.labels_\n",
    "\n",
    "# Select the clusters you want to include in the sample\n",
    "selected_clusters = [1, 3, 5, 9, 10]\n",
    "\n",
    "cluster_series = pd.Series(cluster_assignments)\n",
    "\n",
    "# Create the new DataFrame containing only the rows from the selected clusters\n",
    "sample3 = df[cluster_series.isin(selected_clusters)]\n",
    "\n",
    "sample3['Class'].value_counts() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Systematic Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    255\n",
       "1    254\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interval = 3\n",
    "sample4 = df.iloc[::interval]\n",
    "sample4['Class'].value_counts() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convience Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    403\n",
       "0    397\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample5 = pd.concat([df.head(400), df.tail(400)])\n",
    "sample5['Class'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model M1 (Logistic Regression) on the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing accuracies of M1 on all samples\n",
    "M1_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090909090909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Training M1 on sample1\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample1.drop('Class', axis=1), sample1['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model1 = LogisticRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred1 = model1.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred1)\n",
    "M1_accuracies.append(acc)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9477124183006536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Training M1 on sample2\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample2.drop('Class', axis=1), sample2['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model1 = LogisticRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred1 = model1.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred1)\n",
    "M1_accuracies.append(acc)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Training M1 on sample3\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample3.drop('Class', axis=1), sample3['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model1 = LogisticRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred1 = model1.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred1)\n",
    "M1_accuracies.append(acc)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8823529411764706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Training M1 on sample4\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample4.drop('Class', axis=1), sample4['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model1 = LogisticRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred1 = model1.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred1)\n",
    "M1_accuracies.append(acc)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Training M1 on sample5\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample5.drop('Class', axis=1), sample5['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model1 = LogisticRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred1 = model1.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred1)\n",
    "M1_accuracies.append(acc)\n",
    "print(acc)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model M2 (Random Forest) on the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.974025974025974\n"
     ]
    }
   ],
   "source": [
    "# Training M2 on sample1\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample1.drop('Class', axis=1), sample1['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model2 = RandomForestClassifier()\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred2 = model2.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred2)\n",
    "M2_accuracies.append(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9967320261437909\n"
     ]
    }
   ],
   "source": [
    "# Training M2 on sample2\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample2.drop('Class', axis=1), sample2['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model2 = RandomForestClassifier()\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred2 = model2.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred2)\n",
    "M2_accuracies.append(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.988972\n"
     ]
    }
   ],
   "source": [
    "# Training M2 on sample3\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample3.drop('Class', axis=1), sample3['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model2 = RandomForestClassifier()\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred2 = model2.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred2)\n",
    "M2_accuracies.append(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.935897\n"
     ]
    }
   ],
   "source": [
    "# Training M2 on sample4\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample4.drop('Class', axis=1), sample4['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model2 = RandomForestClassifier()\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred2 = model2.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred2)\n",
    "M2_accuracies.append(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.971526\n"
     ]
    }
   ],
   "source": [
    "# Training M2 on sample5\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample5.drop('Class', axis=1), sample5['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model2 = RandomForestClassifier()\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred2 = model2.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred2)\n",
    "M2_accuracies.append(acc)\n",
    "print(acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model M3 (SVM) on the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "M3_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6363636363636364\n"
     ]
    }
   ],
   "source": [
    "# Training M3 on sample1\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample1.drop('Class', axis=1), sample1['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "model3 = SVC()\n",
    "model3.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred3 = model3.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred3)\n",
    "M3_accuracies.append(acc)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Training M3 on sample2\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample2.drop('Class', axis=1), sample2['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "model3 = SVC()\n",
    "model3.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred3 = model3.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred3)\n",
    "M3_accuracies.append(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65\n"
     ]
    }
   ],
   "source": [
    "# Training M3 on sample3\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample3.drop('Class', axis=1), sample3['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "model3 = SVC()\n",
    "model3.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred3 = model3.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred3)\n",
    "M3_accuracies.append(acc)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Training M3 on sample4\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample4.drop('Class', axis=1), sample4['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "model3 = SVC()\n",
    "model3.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred3 = model3.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred3)\n",
    "M3_accuracies.append(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89375\n"
     ]
    }
   ],
   "source": [
    "# Training M3 on sample5\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample5.drop('Class', axis=1), sample5['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "model3 = SVC()\n",
    "model3.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred3 = model3.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred3)\n",
    "M3_accuracies.append(acc)\n",
    "print(acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model M4 (Decision Trees) on the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "M4_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "# Training M4 on sample1\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample1.drop('Class', axis=1), sample1['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model4 = DecisionTreeClassifier(max_depth=5)\n",
    "model4.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred4 = model4.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred4)\n",
    "M4_accuracies.append(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9836601307189542\n"
     ]
    }
   ],
   "source": [
    "# Training M4 on sample2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample2.drop('Class', axis=1), sample2['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model4 = DecisionTreeClassifier(max_depth=5)\n",
    "model4.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred4 = model4.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred4)\n",
    "M4_accuracies.append(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.955\n"
     ]
    }
   ],
   "source": [
    "# Training M4 on sample3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample3.drop('Class', axis=1), sample3['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model4 = DecisionTreeClassifier(max_depth=5)\n",
    "model4.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred4 = model4.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred4)\n",
    "M4_accuracies.append(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "# Training M4 on sample4\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample4.drop('Class', axis=1), sample4['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model4 = DecisionTreeClassifier(max_depth=5)\n",
    "model4.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred4 = model4.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred4)\n",
    "M4_accuracies.append(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98125\n"
     ]
    }
   ],
   "source": [
    "# Training M4 on sample5\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample5.drop('Class', axis=1), sample5['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model4 = DecisionTreeClassifier(max_depth=5)\n",
    "model4.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred4 = model4.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred4)\n",
    "M4_accuracies.append(acc)\n",
    "print(acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model M5 (KNN) on the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "M5_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7662337662337663\n"
     ]
    }
   ],
   "source": [
    "# Training M5 on sample1\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample1.drop('Class', axis=1), sample1['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "model5 = KNeighborsClassifier(n_neighbors=5)\n",
    "model5.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred5 = model5.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred5)\n",
    "M5_accuracies.append(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8562091503267973\n"
     ]
    }
   ],
   "source": [
    "# Training M5 on sample2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample2.drop('Class', axis=1), sample2['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "model5 = KNeighborsClassifier(n_neighbors=5)\n",
    "model5.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred5 = model5.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred5)\n",
    "M5_accuracies.append(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87\n"
     ]
    }
   ],
   "source": [
    "# Training M5 on sample3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample3.drop('Class', axis=1), sample3['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "model5 = KNeighborsClassifier(n_neighbors=5)\n",
    "model5.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred5 = model5.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred5)\n",
    "M5_accuracies.append(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7941176470588235\n"
     ]
    }
   ],
   "source": [
    "# Training M5 on sample4\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample4.drop('Class', axis=1), sample4['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "model5 = KNeighborsClassifier(n_neighbors=5)\n",
    "model5.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred5 = model5.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred5)\n",
    "M5_accuracies.append(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8875\n"
     ]
    }
   ],
   "source": [
    "# Training M5 on sample5\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample5.drop('Class', axis=1), sample5['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "model5 = KNeighborsClassifier(n_neighbors=5)\n",
    "model5.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred5 = model5.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred5)\n",
    "M5_accuracies.append(acc)\n",
    "print(acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model M6 (Naive Bayes) on the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "M6_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8441558441558441\n"
     ]
    }
   ],
   "source": [
    "# Training M6 on sample1\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample1.drop('Class', axis=1), sample1['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "model6 = GaussianNB()\n",
    "model6.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred6 = model6.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred6)\n",
    "M6_accuracies.append(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8725490196078431\n"
     ]
    }
   ],
   "source": [
    "# Training M6 on sample2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample2.drop('Class', axis=1), sample2['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "model6 = GaussianNB()\n",
    "model6.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred6 = model6.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred6)\n",
    "M6_accuracies.append(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.835\n"
     ]
    }
   ],
   "source": [
    "# Training M6 on sample3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample3.drop('Class', axis=1), sample3['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "model6 = GaussianNB()\n",
    "model6.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred6 = model6.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred6)\n",
    "M6_accuracies.append(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "# Training M6 on sample4\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample4.drop('Class', axis=1), sample4['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "model6 = GaussianNB()\n",
    "model6.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred6 = model6.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred6)\n",
    "M6_accuracies.append(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93125\n"
     ]
    }
   ],
   "source": [
    "# Training M6 on sample5\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample5.drop('Class', axis=1), sample5['Class'], test_size=0.2, random_state=123)\n",
    "\n",
    "model6 = GaussianNB()\n",
    "model6.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test set\n",
    "y_pred6 = model6.predict(X_test)\n",
    "\n",
    "# Find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred6)\n",
    "M6_accuracies.append(acc)\n",
    "print(acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dataframe with the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing Models M1, M2, M4, M5, M6 as they have the highest accuracy\n",
    "\n",
    "# Final results of all models and samples\n",
    "df = pd.DataFrame({'Logistic Regression': M1_accuracies, 'Random Forest': M2_accuracies, 'Decision Tree': M4_accuracies, 'KNN': M5_accuracies, 'Naive Bayes': M6_accuracies}, index=['Sample1', 'Sample2', 'Sample3', 'Sample4', 'Sample5'])\n",
    "# Highlght the best model for each sample\n",
    "# df.style.highlight_max(axis=1, color='lightgreen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample1</th>\n",
       "      <th>Sample2</th>\n",
       "      <th>Sample3</th>\n",
       "      <th>Sample4</th>\n",
       "      <th>Sample5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.947712</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.974026</td>\n",
       "      <td>0.996732</td>\n",
       "      <td>0.988972</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.971526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.983660</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.981250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.856209</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.887500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.872549</td>\n",
       "      <td>0.835000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.931250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Sample1   Sample2   Sample3   Sample4   Sample5\n",
       "Logistic Regression  0.909091  0.947712  0.945000  0.882353  0.950000\n",
       "Random Forest        0.974026  0.996732  0.988972  0.935897  0.971526\n",
       "Decision Tree        0.909091  0.983660  0.955000  0.941176  0.981250\n",
       "KNN                  0.766234  0.856209  0.870000  0.794118  0.887500\n",
       "Naive Bayes          0.844156  0.872549  0.835000  0.833333  0.931250"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Swap rows and columns\n",
    "df = df.transpose()\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
